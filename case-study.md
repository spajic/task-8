За время курса оптимизации я дважды использовал новые знания в двух своих проектах.

# Case study #1

### Проблема в проекте
Первый мой проект - автоматизация управления серверов. На дашборде отображаются все текущие сервера клиентов.
И один из клиентов пожаловался на то, что список серверов на дашборде загружается слишком медленно.

Как оказалось 7 серверов в списке загружались за 3.5 секунды. Хотя обычно на деве и у других клиентов это занимало миллисекунды.

### Анализ и профилирование
Главная точка роста была в index экшене из ServersController. В тот момент прошел первый или второй вебинар и я решил испытать ruby-prof на деле.

**Итерация #1**
Завернул весь index экшен в `RubyProf.profile` и собрал callstack отчет.
Отчет сразу показал, что почти все время занимал один метод в конце экшена. Я посмотрел, что этот метод делает, и оказалось, что такой же метод используется в show экшене... Но для index он вообще был не нужен и можно было его спокойно убрать.

**Итерация #2**
Следующий шаг был разобраться почему из 100 клиентов только у одного за 4 года появилась эта проблема.
Анализ показал, что данный клиент сохраняет кучу метаданных в серверах, которые попадали к нам и тормозили обработку данных в ServersController. Так как метаданные были лишней для нас информацией, мы исключили все лишние данные.

### Результат
index экшен начал работать ~300ms после всех оптимизаций вместо 3.5 секунд. Клиент доволен. И даже через пару недель после того, как количество серверов увеличилось на дашборде, скорость вообще не изменилась для index экшена.

# Case study #2

### Проблема в проекте
Второй мой проект - CRM система для прорабов и строителей для управления кранами и их загрузкой.

Проблема была найдена на staging при формировании графиков по кранам за текущую неделю. При отправке запроса на бэкенд, nginx обрывал запрос после 60 секундного таймаута. После небольшого дебагинга оказалось, что весь запрос занимал 2.5 минуты.

### Анализ и профилирование
Все так же решил использовать `ruby-prof` для сервиса, который вызывался в проблемном экшене.
На локальном деве сервис отрабатывал за 20 секунд и настройки на деве были использованы как `feedback-loop`.

**Итерация #1**
В налаче собрал flat отчет, который показал, что все время было затрачено на какие-то конвертации дат и времени.

**Итерация #2**
Собрал callstack отчет, чтобы понять в каком методе главная точка роста. Обнаружил то, что методы `beginning_of_week` и `end_of_week` из `Date` класс крайне жирные методы, если они в цикле.
Решение: вынесли методы из циклов.

**Итерация #3**
Следующей точкой роста было проверкой того, что время попадает в диапазон двух других дат. При сравнивании дат между собой `Time` класс делал дополнительные конвертации на базе текущей таймзоны, что и было основной проблемой.
Решение: было решено придумать какой другой способ проверки, если время в диапазоне двух дат или нет.
Написал небольшой benchmark с разными вариантами сравнений:
```
t = Time.now
t1 = Time.now - 3600
t2 = Time.now + 3600
t1_int = t1.to_i
t2_int = t2.to_i

Benchmark.ips do |x|
  x.config(:time => 5, :warmup => 5)
  x.report('time') { t.between?(t1, t2) }
  x.report('int') { t.to_i.between?(t1_int, t2_int) }
  x.report('>= and <=') { t >= t1 && t <= t2 }
  x.report('>= and <= int') { t.to_i >= t1_int && t.to_i <= t2_int }
  x.report('range time') { (t1..t2).include?(t) }
  x.report('range int') { (t1_int..t2_int).include?(t.to_i) }
  x.compare!
end

Comparison:
       >= and <= int:  5262224.2 i/s
                 int:  4296030.3 i/s - 1.22x  slower
                time:  3903217.2 i/s - 1.35x  slower
           >= and <=:  3221326.8 i/s - 1.63x  slower
           range int:  2982472.6 i/s - 1.76x  slower
          range time:  2385975.4 i/s - 2.21x  slower

```
Как оказалось, если объекты времени сразу конвертировать в числа и их сравнивать между собой, то это даст прирост в сравнении с другими вариантами.

### Результат
Отработка сервиса упала с 2.5 минуты до 9 секунд. Этого было достаточно в тот момент, так как проблема была критической и надо было ее решить как можно скорее.

На будущее хотелось бы ужать работу сервиса в 1 секунду или меньше, так как можно было переписать выборки из базы и еще оптимизировать работу с объектами времени.
