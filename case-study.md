# Case-study оптимизации mood.travel

## Актуальная проблема
Я занимаюсь разработкой онлайн платформы для бронирования отдыха на Маврикии и при тестировании в продакшен окружении поиска туров я столкнулся c проблемой очень заметного увеличения времени ответа бекэнда. Для бекэнда используется `Rails` приложение в режиме `API` и база данных `PostgreSQL`

Когда в базу данных загружена небольшое количество информации о ценах (3-4 отеля) поиск работает достаточно быстро и не создает ощутимых задержек при поиске. Но и добавлении новых данных скорость стала очень заметно падать.

Для онлайн-платформы это недопустимо, и я решил оптимизировать работы поискового движка.

## Формирование метрики

Для первичного анализа ситуации я использовал `skylite`.
Общее время ответа на запрос составляло чуть менее 2 секунд.
75% времени запроса занимал запрос к базе данных. Это я и буду оптимизировать.

Для построения метрик я использовал `pghero` и `Postgres EXPLAIN Visualizer`.

## Структура данных

Каждый отель, который предоставляет цены на проживание, имеет, как правило, свои особенные условия. К примеру, цена может быть за номер или за человека. Именно с калькуляцией цены за человека и возникают основный трудности. Ниже несколько вариантов цен от отеля:

```
single - 100 EURO, 1/2 double - 45 EURO, Additional adult - 30 EUR
single - 100 EURO, double - 90 EURO, 3 adults - 120 EUR
```

Из приведённого примера видно, что отели указывают цены за номер разными несколькими способами. Поэтому для упрощения калькуляции цен данные преобразуются в единый формат и сохраняются в отдельной таблице в виде заранее посчитанных цен по количеству проживающих в номере. В этой же таблице указывалась сопутствующая информация по ценам на питания, отмене бронирования итд.

```
Часть структуры хранения для периода действия цены и для вместимости комнаты:

date_periods: [
    {
        from: '01-01-2019',
        to: '31-01-2019'
    }, {
        from: '01-05-2019',
        to: '31-05-2019'
    }
],
combination: [
    {
        "to": 99,
        "from": 12,
        "count": 2
    },
    {
        "to": 2,
        "from": 0,
        "count": 0
    },
    {
        "to": 7,
        "from": 3,
        "count": 0
    },
    {
        "to": 11,
        "from": 8,
        "count": 2
    }
],
price: 280
```

## Построение Feedback-Loop

Для тестов был выбран вариант загрузки данных в объеме 30 отелей и было настроено локальное продакшен окружения. В качестве `Feedback-loop` я использовал метрики из `pghero`.  

## Ищем точки роста

Для поиска я использовал `Postgres EXPLAIN Visualizer`.
Вот что я обнаружил:

### Первая находка

Большего всего времени занимал анализ подходит запрошенный вариант размещения для записи в базе данных или нет.

```
WHERE (IS_ROOM_FIT_GUESTS_AND_IS_VALID_PERIOD(ARRAY[18,18,1,3]::INT[], combination, date_periods, '10-01-2019'::date, '20-01-2019'::date) = TRUE
```

Поиск был сделан с помощью функции, которая сравнивала пересекается ли запрошенный период проживания и совпадает ли запрошенный вариант вместимости с записью в базе с помощью `FOREACH`. Такой вариант запроса невозможно проиндексировать или оптимизировать.
Поэтому для оптимизации запроса я изменил структуру хранения данных. Чтобы избежать перебора массива с валидными периодами, я разделил массив на отдельные записи.

Вместо одного поля в таблице
```
date_periods: [
    {
        from: '01-01-2019',
        to: '31-01-2019'
    }, {
        from: '01-05-2019',
        to: '31-05-2019'
    }
]
```

стало два поля:
```
from: '01-01-2019', to: '31-01-2019'
```
и запрос упростился до простейшего сравнения
```
date_from < :check_out::date AND date_to >= :check_in::date
```

Такое решение улучшило ответ с 1.7 сек до 1.2 сек

### Вторая находка

Дальше я решил полностью отказаться от использования функции в запросе и переписал на чистом SQL проверку вместимости комнаты. Вот пример запроса.

```
(
	SELECT SUM((J->'COUNT')::INT)
 	FROM JSONB_ARRAY_ELEMENTS(combination) J
)::INT = 3
AND
(
	SELECT SUM((J->'COUNT')::INT)
 	FROM JSONB_ARRAY_ELEMENTS(combination) J
 	WHERE (J->'COUNT')::INT = (
  			SELECT COUNT(*)
			  FROM UNNEST('{18,18,1}'::INTEGER[]) AS AGE
  			WHERE AGE >= (J->>'FROM')::INT AND AGE <= (J->>'TO')::INT
		)::INT
	)::INT = 3
```

Такое решение улучшило ответ с 1.2 сек до 0.6 сек

### Третья находка

Одной из проверок в запросе было сравнение общего количества проживающих в номере.
```
(SELECT SUM((J->'COUNT')::INT) FROM JSONB_ARRAY_ELEMENTS(combination) J )::INT = 3
```

Так как это константа, вынес ее отдельное поле.
```
WHERE MAX_CAPACITY = 3
```

Такое решение улучшило ответ с 0.6 сек до 0.4 сек

### Четвертая находка

После этого метрика показывала, что узким местом остается использование `UNNEST`.
Запрос был переписан с использованием сравнения `OR` и `AND`.

```
(SELECT SUM((J->'COUNT')::INT)
 	FROM JSONB_ARRAY_ELEMENTS(ACCOMMODATION_TESTS.CAPACITY) J
 	WHERE
	(18 >= (J->>'FROM')::INT AND 18 <= (J->>'TO')::INT AND (J->'COUNT')::INT = 2)
	OR
	(1 >= (J->>'FROM')::INT AND 1 <= (J->>'TO')::INT AND (J->'COUNT')::INT = 1)
)::INT = 3
```

Итоговое время сократилось очень сильно и составило 184 ms

## Итоги и выводы

Несмотря на то, что база данных `PostgreSQL` оптимизирована на работу с `jsonb`, использование простых операторов таких как `OR`, `AND` итд с использованием индексов даст гораздо более быстрый ответ от базы данных.
